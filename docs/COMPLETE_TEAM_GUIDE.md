# CaseTracker Pro - Complete Team Onboarding Guide

## Table of Contents
1. [Project Overview](#project-overview)
2. [Technology Stack & Rationale](#technology-stack--rationale)
3. [Architecture Overview](#architecture-overview)
4. [Core Features Deep Dive](#core-features-deep-dive)
5. [Development Setup](#development-setup)
6. [Authentication & Security](#authentication--security)
7. [API Integration](#api-integration)
8. [Page-by-Page Guide](#page-by-page-guide)
9. [Database Schema](#database-schema)
10. [Deployment & Operations](#deployment--operations)
11. [Troubleshooting & Debugging](#troubleshooting--debugging)
12. [Best Practices](#best-practices)
13. [Quick Reference](#quick-reference)

---

## Project Overview

**CaseTracker Pro** is a medical report generation system that transforms case data into comprehensive medical reports using AI-powered analysis. The system serves medical professionals by automating the complex process of medical document analysis and report generation.

### Business Value
- **Time Efficiency**: Reduces manual report creation from hours to minutes
- **AI-Powered Analysis**: Leverages advanced AI for comprehensive medical document processing
- **Centralized Management**: Single platform for all case-related documents and reports
- **Version Control**: Track changes and compare different versions of Life Care Plans (LCPs)

### Key Metrics
- **Report Generation Time**: ~2 hours per case
- **Document Processing**: 10,000+ documents handled
- **User Base**: 100+ medical professionals
- **System Uptime**: 99.9%

---

## Technology Stack & Rationale

### Frontend: Streamlit 1.28.1
**Why Streamlit?**
- **Rapid Development**: Build data apps with minimal code
- **Python-Native**: Perfect fit for AI and data science workflows
- **Rich UI Components**: Built-in widgets without complex frontend setup
- **Real-time Updates**: Automatic UI refresh based on data changes
- **Easy Deployment**: Simple deployment to cloud platforms

### Backend: FastAPI 0.104.1
**Why FastAPI?**
- **High Performance**: Async support, built on Starlette
- **Automatic Documentation**: OpenAPI/Swagger docs generated automatically
- **Type Safety**: Full Python type hints support
- **Modern Python**: Leverages async/await for concurrent operations
- **Easy Testing**: Built-in testing support with pytest

### Database: SQLite
**Why SQLite?**
- **Zero Configuration**: No separate database server needed
- **Portable**: Single file database, easy backup and migration
- **Sufficient Scale**: Perfect for current user load and data volume
- **ACID Compliant**: Full transaction support
- **Python Integration**: Excellent native Python support

### Cloud Storage: AWS S3
**Why AWS S3?**
- **Scalability**: Virtually unlimited storage capacity
- **Durability**: 99.999999999% durability guarantee
- **Security**: Fine-grained access controls with IAM
- **Integration**: Excellent Python SDK (boto3) support
- **Cost Effective**: Pay-as-you-go pricing model

### Authentication: Custom Implementation
**Why Custom Auth?**
- **Simple Requirements**: No need for complex OAuth flows initially
- **Full Control**: Complete control over user data and authentication logic
- **Flexibility**: Easy to extend with role-based access later
- **Privacy**: No third-party authentication services

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit     â”‚    â”‚    FastAPI      â”‚    â”‚     AWS S3     â”‚
â”‚   Frontend      â”‚â—„â”€â”€â–ºâ”‚    Backend      â”‚â—„â”€â”€â–ºâ”‚   Storage       â”‚
â”‚   (Port 8501)   â”‚    â”‚   (Port 8000)   â”‚    â”‚   (Documents)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Session  â”‚    â”‚   SQLite DB      â”‚    â”‚   N8n Workflow  â”‚
â”‚   Management    â”‚    â”‚  (reports.db)    â”‚    â”‚   (AI Processing)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

#### Frontend (Streamlit Pages)
- **main.py**: Landing page and navigation hub
- **pages/01_Case_Report.py**: Case report generation
- **pages/02_Deposition.py**: Document viewer
- **pages/04_Results.py**: Results display and download
- **pages/05_History.py**: Case history and tracking
- **pages/06_Version_Comparison.py**: LCP version comparison

#### Backend (FastAPI)
- **backend/main.py**: Main API server with all endpoints
- **backend/n8n_integration.py**: N8n workflow integration
- **SQLite Database**: Metadata storage for reports and users

#### Supporting Modules
- **app/auth.py**: Authentication system
- **app/ui.py**: UI components and styling
- **app/s3_utils.py**: S3 integration utilities
- **app/version_comparison.py**: Document comparison logic

---

## Core Features Deep Dive

### 1. Case Report Generation
**Purpose**: Generate comprehensive medical reports using AI analysis

**Workflow**:
1. User enters 4-digit Case ID
2. System validates case exists in S3
3. Triggers N8n workflow for AI processing
4. Tracks progress with real-time updates
5. Notifies user when complete (typically 2 hours)

**Technical Implementation**:
```python
# Key functions in 01_Case_Report.py
def _validate_case_id_exists(case_id: str) -> dict:
    """Check if case ID exists in S3 database"""
    
def _trigger_report_generation(case_id: str, user_email: str) -> dict:
    """Trigger N8n workflow for AI processing"""
    
def _start_backend_pinger(backend_url: str):
    """Keep backend alive during long-running processes"""
```

**Key Features**:
- Real-time progress tracking with session state
- Backend pinger to prevent timeouts during 2-hour processing
- Comprehensive error handling and retry logic
- Debug mode for testing (Case ID: 0000)

### 2. Deposition Document Viewer
**Purpose**: Browse and view source documents for each case

**Features**:
- Document grouping by provider/source using filename patterns
- Built-in image viewer with zoom capabilities
- PDF and DOCX support with inline preview
- Download capabilities for all document types
- Responsive design for mobile and desktop

**Technical Details**:
```python
# Document grouping logic
def group_documents_by_provider(documents: List[Dict]) -> Dict[str, List[Dict]]:
    """Group documents by provider using filename patterns"""
    for doc in documents:
        filename = doc.get("filename", "")
        if "__grp-" in filename:
            match = re.search(r"__grp-(.+?)__src", filename)
            if match:
                provider = match.group(1).strip()
```

### 3. Results Dashboard
**Purpose**: View and download generated reports

**Features**:
- Real-time generation status with automatic refresh
- Patient name extraction from S3 keys
- Report preview with inline viewer
- Download options (PDF, DOCX formats)
- Performance metrics and analytics

**State Management**:
```python
# Session state for progress tracking
st.session_state.generation_complete = False
st.session_state.generation_progress = 0
st.session_state.generation_start = datetime.now()
st.session_state.generation_failed = False
```

### 4. History Tracking
**Purpose**: Track all report generation history

**Features**:
- Complete case history with filtering and search
- Status tracking (pending, processing, completed, failed)
- Export capabilities for audit trails
- Usage analytics and performance metrics
- Advanced search by date, status, case ID

**Database Operations**:
```python
def get_report_history(filters: dict = None) -> List[Dict]:
    """Fetch reports from database with optional filters"""
    conn = get_conn()
    query = "SELECT * FROM reports"
    if filters:
        query += build_where_clause(filters)
    return conn.execute(query).fetchall()
```

### 5. Version Comparison
**Purpose**: Compare different versions of LCP documents

**Features**:
- Side-by-side document comparison
- Section-by-section change tracking
- Visual diff display with highlighting
- Export comparison results
- Version history tracking

**Technical Implementation**:
```python
class LCPVersionComparator:
    def compare_versions(self, case_id: str, version1: str, version2: str):
        """Compare two versions of LCP documents"""
        v1_content = self.fetch_version(case_id, version1)
        v2_content = self.fetch_version(case_id, version2)
        return self.generate_diff(v1_content, v2_content)
```

---

## Development Setup

### Prerequisites
- Python 3.8+
- Git
- AWS Account (for S3)
- N8n instance (for AI workflows)

### Local Development Setup

1. **Clone Repository**
```bash
git clone <repository-url>
cd basic-streamlit-ui
```

2. **Install Dependencies**
```bash
pip install -r requirements.txt
```

3. **Environment Configuration**
```bash
# Copy example configuration
cp .env.example .env
# Edit .env with your settings
```

4. **Start Backend Server**
```bash
cd backend
python main.py
# Backend runs on http://localhost:8000
```

5. **Start Frontend**
```bash
# In main directory
streamlit run main.py
# Frontend runs on http://localhost:8501
```

### Environment Variables

```bash
# AWS Configuration
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_REGION=us-east-1
S3_BUCKET_NAME=your_bucket_name

# Backend Configuration
BACKEND_BASE=http://localhost:8000

# N8n Configuration
N8N_WEBHOOK_URL=your_n8n_webhook_url
N8N_AUTH_TOKEN=your_n8n_token
```

### Project Structure
```
basic-streamlit-ui/
â”œâ”€â”€ ðŸ“„ main.py                 # Main dashboard and navigation
â”œâ”€â”€ ðŸ“ pages/                  # Streamlit pages
â”‚   â”œâ”€â”€ ðŸ“„ 01_Case_Report.py   # Report generation
â”‚   â”œâ”€â”€ ðŸ“„ 02_Deposition.py    # Document viewer
â”‚   â”œâ”€â”€ ðŸ“„ 04_Results.py       # Results display
â”‚   â”œâ”€â”€ ðŸ“„ 05_History.py       # Case history
â”‚   â””â”€â”€ ðŸ“„ 06_Version_Comparison.py # LCP comparison
â”œâ”€â”€ ðŸ“ app/                    # Shared components
â”‚   â”œâ”€â”€ ðŸ“„ auth.py             # Authentication logic
â”‚   â”œâ”€â”€ ðŸ“„ ui.py               # UI components & styling
â”‚   â”œâ”€â”€ ðŸ“„ s3_utils.py         # S3 integration
â”‚   â””â”€â”€ ðŸ“„ version_comparison.py # Document comparison
â”œâ”€â”€ ðŸ“ backend/                # FastAPI backend
â”‚   â”œâ”€â”€ ðŸ“„ main.py             # API server
â”‚   â””â”€â”€ ðŸ“„ n8n_integration.py  # N8n workflow integration
â”œâ”€â”€ ðŸ“„ config.yaml             # User credentials
â”œâ”€â”€ ðŸ“„ requirements.txt        # Python dependencies
â””â”€â”€ ðŸ“„ .env                    # Environment variables
```

---

## Authentication & Security

### Current Implementation
- **Simple Username/Password**: Basic authentication using bcrypt
- **Session Management**: Streamlit session state
- **Role-Based Access**: Admin and user roles
- **Password Hashing**: bcrypt for secure password storage

### User Management
Users are defined in `config.yaml`:
```yaml
credentials:
  usernames:
    user_name:
      email: user@example.com
      name: Display Name
      password: $2b$12$hashed_password
```

### Authentication Flow
```python
# In app/auth.py
def verify_credentials(email: str, password: str) -> bool:
    """Verify user credentials against stored hashes"""
    email = email.strip().lower()
    if email not in CREDENTIALS:
        return False
    password_hash = hash_password(password)
    return password_hash == CREDENTIALS[email]["password_hash"]
```

### Security Best Practices
1. **Password Security**: All passwords are bcrypt hashed
2. **Session Timeout**: Sessions expire after inactivity
3. **Input Validation**: All user inputs are validated
4. **CORS Protection**: Backend configured for specific origins
5. **S3 Security**: IAM roles with least privilege
6. **SQL Injection**: Parameterized queries only
7. **XSS Protection**: User content sanitization

### Future Security Enhancements
- OAuth 2.0 integration (Google, Microsoft)
- Multi-factor authentication
- Role-based permissions system
- Comprehensive audit logging
- Session encryption
- API rate limiting

---

## API Integration

### Backend API Endpoints

#### Core Endpoints
```python
GET  /health                    # Health check
GET  /s3/cases                  # List available cases
GET  /s3/case/{case_id}/report  # Get case report
POST /generate/{case_id}        # Start report generation
GET  /reports                   # Get all reports
GET  /reports/{case_id}         # Get specific report
```

#### Document Endpoints
```python
GET  /proxy/docx                # Proxy DOCX files (CORS)
GET  /docx/extract-text         # Extract text from DOCX
GET  /s3/documents/{case_id}   # List case documents
```

#### Database Endpoints
```python
GET  /reports                   # Get all reports
POST /reports                   # Create report entry
PUT  /reports/{id}              # Update report status
DELETE /reports/{id}            # Delete report
```

### N8n Integration
The system integrates with N8n for AI processing workflows:

**Workflow Trigger**:
```python
POST /n8n/webhook/generate-report
{
    "case_id": "1234",
    "user_email": "user@example.com",
    "timestamp": "2024-01-01T12:00:00Z"
}
```

**Workflow Steps**:
1. Receive case ID and user information
2. Fetch documents from S3 storage
3. Process documents with AI models
4. Generate comprehensive report
5. Store results in S3 and database
6. Send completion notification

**Callback Handling**:
```python
@app.post("/webhook/report-complete")
def handle_report_completion(payload: dict):
    """Handle N8n workflow completion callback"""
    case_id = payload.get("case_id")
    status = payload.get("status")
    report_url = payload.get("report_url")
    
    # Update database
    conn = get_conn()
    conn.execute(
        "UPDATE reports SET status = ?, completed_at = ?, report_url = ? WHERE case_id = ?",
        (status, datetime.now(), report_url, case_id)
    )
```

---

## Page-by-Page Guide

### Main Dashboard (`main.py`)
**Purpose**: Central navigation hub and user interface

**Key Functions**:
```python
def main():
    # Authentication check
    if not is_authenticated():
        show_login_page()
        return
    
    # Page configuration
    st.set_page_config(
        page_title="CaseTracker Pro",
        page_icon="ðŸ“‹",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # UI rendering
    show_header(...)
    navigation_buttons()
    feature_cards()
    quick_start_guide()
```

**Features**:
- User authentication check and redirect
- Navigation buttons to all main features
- Feature overview cards with descriptions
- Quick start guide for new users
- User profile display in sidebar

### Case Report Generation (`pages/01_Case_Report.py`)
**Purpose**: Generate new medical reports using AI

**Key Functions**:
```python
def _validate_case_id_exists(case_id: str) -> dict:
    """Check if case ID exists in S3"""
    if str(case_id) == "0000":  # Debug mode
        return {"exists": True, "message": "Debug mode"}
    
    backend = _get_backend_base()
    response = requests.get(f"{backend}/s3/cases", timeout=10)
    return response.json()

def _trigger_report_generation(case_id: str, user_email: str) -> dict:
    """Trigger N8n workflow for AI processing"""
    backend = _get_backend_base()
    payload = {
        "case_id": case_id,
        "user_email": user_email,
        "timestamp": datetime.now().isoformat()
    }
    response = requests.post(f"{backend}/generate/{case_id}", json=payload)
    return response.json()
```

**Workflow**:
1. User enters Case ID (4 digits)
2. System validates case exists in S3
3. Triggers N8n workflow for AI processing
4. Shows real-time progress bar
5. Redirects to Results page when complete

**Special Features**:
- Debug mode using Case ID "0000"
- Backend pinger to prevent timeouts
- Comprehensive error handling
- Progress tracking with session state

### Deposition Viewer (`pages/02_Deposition.py`)
**Purpose**: View and browse source documents

**Key Functions**:
```python
def group_documents_by_provider(documents: List[Dict]) -> Dict[str, List[Dict]]:
    """Group documents by provider using filename patterns"""
    grouped = {}
    for doc in documents:
        filename = doc.get("filename", "")
        provider = extract_provider_from_filename(filename)
        if provider not in grouped:
            grouped[provider] = []
        grouped[provider].append(doc)
    return grouped

@st.cache_data(ttl=120)
def fetch_deposition_cases() -> List[str]:
    """Fetch available cases with deposition documents"""
    backend = _get_backend_base()
    response = requests.get(f"{backend}/s3/cases/deposition", timeout=5)
    return response.json().get("cases", [])
```

**Features**:
- Document listing with provider grouping
- Built-in image viewer with zoom
- PDF and DOCX preview
- Download capabilities
- Responsive design

### Results Dashboard (`pages/04_Results.py`)
**Purpose**: Display generated reports and status

**Key Functions**:
```python
def _check_generation_status(case_id: str) -> dict:
    """Check if report generation is complete"""
    return {
        "complete": st.session_state.get("generation_complete", False),
        "progress": st.session_state.get("generation_progress", 0),
        "started": st.session_state.get("generation_start") is not None,
        "failed": st.session_state.get("generation_failed", False)
    }

def _extract_patient_from_strings(case_id: str, gt_key: str = None) -> str:
    """Extract patient name from S3 key patterns"""
    patterns = [
        rf"{case_id}_LCP_([^_]+(?:\s+[^_]+)*?)(?:_|\.)",
        rf"{case_id}_([^_]+(?:\s+[^_]+)*?)(?:_|\.)"
    ]
    for pattern in patterns:
        match = re.search(pattern, gt_key)
        if match:
            return match.group(1).strip()
```

**Features**:
- Real-time status updates
- Report preview with inline viewer
- Download options (PDF, DOCX)
- Patient information extraction
- Performance metrics

### History Page (`pages/05_History.py`)
**Purpose**: Track all report generation history

**Key Functions**:
```python
def get_report_history(filters: dict = None) -> List[Dict]:
    """Fetch report history from database"""
    conn = get_conn()
    query = "SELECT * FROM reports"
    if filters:
        query += build_where_clause(filters)
    query += " ORDER BY created_at DESC"
    return conn.execute(query).fetchall()

def export_history(format: str = "csv") -> bytes:
    """Export history data in specified format"""
    # Implementation for CSV/Excel export
```

**Features**:
- Complete case listing with pagination
- Advanced search and filtering
- Export capabilities (CSV, Excel)
- Usage analytics and metrics
- Status tracking visualization

### Version Comparison (`pages/06_Version_Comparison.py`)
**Purpose**: Compare different versions of LCP documents

**Key Functions**:
```python
class LCPVersionComparator:
    def compare_versions(self, case_id: str, version1: str, version2: str):
        """Compare two versions of LCP documents"""
        v1_content = self.fetch_version(case_id, version1)
        v2_content = self.fetch_version(case_id, version2)
        return self.generate_diff(v1_content, v2_content)
    
    def generate_diff(self, content1: str, content2: str) -> Dict:
        """Generate visual diff between two contents"""
        # Implementation of diff algorithm
```

**Features**:
- Side-by-side document comparison
- Section-by-section change tracking
- Visual diff with highlighting
- Export comparison results
- Version history management

---

## Database Schema

### SQLite Database Structure

```sql
-- Reports table
CREATE TABLE reports (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    case_id TEXT NOT NULL,
    status TEXT NOT NULL CHECK (status IN ('pending', 'processing', 'completed', 'failed')),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP NULL,
    report_url TEXT NULL,
    metadata TEXT NULL,  -- JSON metadata
    user_email TEXT NOT NULL,
    FOREIGN KEY (user_email) REFERENCES users(email)
);

-- Users table
CREATE TABLE users (
    email TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    password_hash TEXT NOT NULL,
    role TEXT NOT NULL DEFAULT 'user' CHECK (role IN ('admin', 'user')),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_login TIMESTAMP NULL
);

-- Sessions table
CREATE TABLE sessions (
    session_id TEXT PRIMARY KEY,
    user_email TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    expires_at TIMESTAMP NOT NULL,
    session_data TEXT NULL,  -- JSON session data
    FOREIGN KEY (user_email) REFERENCES users(email)
);

-- Case documents table
CREATE TABLE case_documents (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    case_id TEXT NOT NULL,
    filename TEXT NOT NULL,
    s3_key TEXT NOT NULL,
    provider TEXT NULL,
    uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    document_type TEXT NULL,
    file_size INTEGER NULL,
    FOREIGN KEY (case_id) REFERENCES reports(case_id)
);

-- Indexes for performance
CREATE INDEX idx_reports_case_id ON reports(case_id);
CREATE INDEX idx_reports_status ON reports(status);
CREATE INDEX idx_reports_created_at ON reports(created_at);
CREATE INDEX idx_sessions_user_email ON sessions(user_email);
CREATE INDEX idx_sessions_expires_at ON sessions(expires_at);
CREATE INDEX idx_case_documents_case_id ON case_documents(case_id);
```

### Database Operations

**Connection Management**:
```python
def get_conn() -> sqlite3.Connection:
    """Get database connection with row factory"""
    conn = sqlite3.connect("reports.db")
    conn.row_factory = sqlite3.Row
    return conn
```

**Common Queries**:
```python
# Get user reports
def get_user_reports(user_email: str) -> List[Dict]:
    conn = get_conn()
    cursor = conn.execute(
        "SELECT * FROM reports WHERE user_email = ? ORDER BY created_at DESC",
        (user_email,)
    )
    return cursor.fetchall()

# Update report status
def update_report_status(case_id: str, status: str, metadata: dict = None):
    conn = get_conn()
    conn.execute(
        "UPDATE reports SET status = ?, metadata = ? WHERE case_id = ?",
        (status, json.dumps(metadata) if metadata else None, case_id)
    )
    conn.commit()
```

---

## Deployment & Operations

### Production Deployment (Render)

**Configuration**:
```yaml
# render.yaml
services:
  - type: web
    name: case-tracker-pro
    env: python
    buildCommand: pip install -r requirements.txt
    startCommand: streamlit run main.py --server.port $PORT
    envVars:
      - key: PORT
        value: 10000
      - key: BACKEND_BASE
        value: http://localhost:8000
```

**Deployment Steps**:
1. **Repository Setup**: Connect GitHub repository to Render
2. **Environment Configuration**: Set all required environment variables
3. **Build Process**: Automatic dependency installation
4. **Health Checks**: Built-in health monitoring
5. **SSL/TLS**: Automatic certificate management
6. **Scaling**: Horizontal scaling with load balancers

### Docker Deployment

**Dockerfile**:
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8501

CMD ["streamlit", "run", "main.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

**docker-compose.yml**:
```yaml
version: '3.8'
services:
  frontend:
    build: .
    ports:
      - "8501:8501"
    environment:
      - BACKEND_BASE=http://backend:8000
    depends_on:
      - backend
  
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
```

### Monitoring & Logging

**Health Checks**:
```python
@app.get("/health")
def health() -> Dict[str, Any]:
    """Comprehensive health check"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "database": check_database_health(),
        "s3": check_s3_health(),
        "n8n": check_n8n_health()
    }
```

**Logging Strategy**:
- **Application Logs**: Structured logging with JSON format
- **Error Tracking**: Comprehensive error handling and reporting
- **Performance Metrics**: Response time and resource usage monitoring
- **User Actions**: Audit trail for all user interactions

### Backup & Recovery

**Database Backups**:
```bash
# Automated daily backup
sqlite3 reports.db ".backup backup_$(date +%Y%m%d).db"

# Restore from backup
cp backup_20240101.db reports.db
```

**S3 Backup Strategy**:
- **Versioning**: Enable S3 bucket versioning
- **Cross-Region Replication**: Replicate to backup region
- **Lifecycle Policies**: Archive old documents to Glacier
- **Access Logs**: Enable S3 access logging

---

## Troubleshooting & Debugging

### Common Issues & Solutions

#### Backend Connection Issues
**Problem**: Frontend can't connect to backend
**Symptoms**: Connection timeout, API errors
**Solutions**:
1. Check backend is running on port 8000
2. Verify BACKEND_BASE environment variable
3. Check CORS configuration in FastAPI
4. Review firewall settings
5. Test with curl: `curl http://localhost:8000/health`

#### S3 Connection Issues
**Problem**: Can't access S3 resources
**Symptoms**: Access denied, timeout errors
**Solutions**:
1. Verify AWS credentials in environment variables
2. Check bucket permissions and IAM policies
3. Verify region configuration
4. Test with AWS CLI: `aws s3 ls`
5. Check bucket exists and is accessible

#### Authentication Issues
**Problem**: Users can't log in
**Symptoms**: Invalid credentials, session issues
**Solutions**:
1. Check config.yaml format and syntax
2. Verify password hashes are correct
3. Clear session state: `st.session_state.clear()`
4. Review auth.py logic for validation
5. Test with known good credentials

#### Report Generation Issues
**Problem**: Reports not generating or failing
**Symptoms**: Stuck in processing, failed status
**Solutions**:
1. Check N8n webhook URL and authentication
2. Verify case ID exists in S3
3. Review backend logs for errors
4. Check S3 document availability
5. Test with debug case ID "0000"

### Debug Mode

**Using Debug Case ID**:
```python
# Special case for testing
if str(case_id) == "0000":
    return {
        "exists": True,
        "message": "Debug mode - bypassing S3 validation",
        "error": None
    }
```

**Debug Features**:
- Bypasses S3 validation
- Simulates report generation
- Immediate completion for testing
- Useful for development and UI testing

### Log Analysis

**Backend Logs**:
```bash
# Start backend with debug logging
cd backend && python main.py

# Check for specific errors
grep -i error backend.log
grep -i exception backend.log
```

**Frontend Logs**:
```bash
# Start Streamlit with debug level
streamlit run main.py --logger.level debug

# Check browser console for JavaScript errors
```

**Database Issues**:
```bash
# Check database integrity
sqlite3 reports.db "PRAGMA integrity_check;"

# Check table structure
sqlite3 reports.db ".schema"
```

---

## Best Practices

### Code Organization

**Modular Structure**:
- Separate concerns into logical modules
- Use consistent naming conventions
- Implement proper error handling
- Add comprehensive documentation
- Use type hints throughout

**Example Structure**:
```python
# Good example
from typing import Dict, List, Optional
import logging

def validate_case_id(case_id: str) -> Dict[str, Any]:
    """
    Validate case ID format and existence.
    
    Args:
        case_id: 4-digit case identifier
        
    Returns:
        Dictionary with validation results
        
    Raises:
        ValueError: If case_id format is invalid
    """
    if not case_id.isdigit() or len(case_id) != 4:
        raise ValueError("Case ID must be 4 digits")
    
    # Additional validation logic
    return {"valid": True, "case_id": case_id}
```

### Performance Optimization

**Caching Strategies**:
```python
# Streamlit caching for expensive operations
@st.cache_data(ttl=300)  # 5 minutes
def fetch_cases_from_s3() -> List[str]:
    """Fetch available cases with caching"""
    # Expensive S3 operation
    return s3_manager.list_cases()

# Backend caching for API responses
from functools import lru_cache

@lru_cache(maxsize=128)
def get_user_permissions(user_email: str) -> List[str]:
    """Cache user permissions"""
    return database.get_permissions(user_email)
```

**Database Optimization**:
```python
# Use indexes for common queries
CREATE INDEX idx_reports_user_status ON reports(user_email, status);

# Use parameterized queries
def get_user_reports(user_email: str, limit: int = 50) -> List[Dict]:
    conn = get_conn()
    cursor = conn.execute(
        "SELECT * FROM reports WHERE user_email = ? ORDER BY created_at DESC LIMIT ?",
        (user_email, limit)
    )
    return cursor.fetchall()
```

### Security Practices

**Input Validation**:
```python
def validate_case_id(case_id: str) -> bool:
    """Validate case ID input"""
    if not case_id or not isinstance(case_id, str):
        return False
    return case_id.isdigit() and len(case_id) == 4

def sanitize_filename(filename: str) -> str:
    """Sanitize filename for security"""
    # Remove path traversal attempts
    filename = filename.replace("..", "").replace("/", "").replace("\\", "")
    # Limit length
    return filename[:255]
```

**Error Handling**:
```python
try:
    result = risky_operation()
except SpecificException as e:
    logger.error(f"Specific error occurred: {e}")
    st.error("Operation failed. Please try again.")
except Exception as e:
    logger.error(f"Unexpected error: {e}")
    st.error("An unexpected error occurred.")
    # Don't expose internal details to user
```

### Testing Strategy

**Unit Tests**:
```python
import pytest
from app.auth import verify_credentials

def test_verify_credentials_valid():
    """Test valid credential verification"""
    assert verify_credentials("admin@casetracker.com", "password123")

def test_verify_credentials_invalid():
    """Test invalid credential verification"""
    assert not verify_credentials("invalid@test.com", "wrongpassword")
```

**Integration Tests**:
```python
def test_case_report_generation():
    """Test complete report generation flow"""
    # Setup
    case_id = "0000"  # Debug mode
    
    # Execute
    response = client.post(f"/generate/{case_id}")
    
    # Verify
    assert response.status_code == 200
    assert response.json()["status"] == "started"
```

### Development Workflow

**Git Workflow**:
```bash
# Feature branch development
git checkout -b feature/new-feature
git add .
git commit -m "feat: add new feature"
git push origin feature/new-feature

# Create pull request for review
# Merge to main after approval
```

**Code Review Checklist**:
- [ ] Code follows style guidelines
- [ ] Tests are included and passing
- [ ] Documentation is updated
- [ ] Security implications are considered
- [ ] Performance impact is assessed
- [ ] Error handling is comprehensive

---

## Quick Reference

### Common Commands

**Development**:
```bash
# Install dependencies
pip install -r requirements.txt

# Start backend server
cd backend && python main.py

# Start frontend
streamlit run main.py

# Run tests
python -m pytest

# Check code style
flake8 app/ backend/
```

**Database Operations**:
```bash
# Check database
sqlite3 reports.db ".tables"

# Run query
sqlite3 reports.db "SELECT * FROM reports LIMIT 5;"

# Backup database
sqlite3 reports.db ".backup backup_$(date +%Y%m%d).db"
```

**AWS Operations**:
```bash
# List S3 buckets
aws s3 ls

# List bucket contents
aws s3 ls s3://your-bucket/

# Test credentials
aws sts get-caller-identity
```

### Environment Variables

```bash
# Required for development
AWS_ACCESS_KEY_ID=your_key
AWS_SECRET_ACCESS_KEY=your_secret
AWS_REGION=us-east-1
S3_BUCKET_NAME=your_bucket
BACKEND_BASE=http://localhost:8000

# Optional
N8N_WEBHOOK_URL=your_webhook
N8N_AUTH_TOKEN=your_token
LOG_LEVEL=INFO
```

### API Endpoints

```python
# Core endpoints
GET  /health                    # Health check
GET  /s3/cases                  # List cases
POST /generate/{case_id}        # Generate report
GET  /reports                   # Get reports

# Document endpoints
GET  /proxy/docx                # Proxy DOCX files
GET  /s3/documents/{case_id}   # List documents

# Authentication
POST /login                     # User login
POST /logout                    # User logout
GET  /user/profile              # User profile
```

### Debug Mode

**Using Debug Case ID**:
- Enter "0000" as Case ID
- Bypasses S3 validation
- Simulates immediate report generation
- Perfect for UI testing

### Default Credentials

**Development Users**:
```yaml
# From config.yaml
admin@casetracker.com: password123
analyst@casetracker.com: password456
```

### Performance Tips

1. **Use Caching**: Implement Streamlit caching for expensive operations
2. **Optimize Queries**: Add database indexes for common queries
3. **Lazy Loading**: Load data only when needed
4. **Compress Images**: Optimize image sizes for faster loading
5. **Monitor Resources**: Keep an eye on memory and CPU usage

### Security Checklist

- [ ] Validate all user inputs
- [ ] Use parameterized SQL queries
- [ ] Sanitize user-generated content
- [ ] Implement proper session management
- [ ] Use HTTPS in production
- [ ] Regularly update dependencies
- [ ] Implement proper error handling
- [ ] Use environment variables for secrets

---

## Support & Resources

### Getting Help
- **Documentation**: This comprehensive guide
- **Code Comments**: Inline documentation in source code
- **GitHub Issues**: Report bugs and request features
- **Team Communication**: Slack/Teams channel
- **Emergency Contact**: Lead developer

### Learning Resources
- **Streamlit Documentation**: https://docs.streamlit.io/
- **FastAPI Documentation**: https://fastapi.tiangolo.com/
- **AWS S3 Documentation**: https://docs.aws.amazon.com/s3/
- **Python Best Practices**: PEP 8 style guide

### Community
- **Streamlit Community**: https://discuss.streamlit.io/
- **FastAPI GitHub**: https://github.com/tiangolo/fastapi
- **Python Community**: Stack Overflow, Reddit

---

*Last Updated: January 2025*
*Version: 1.0.0*
*Maintained by: CaseTracker Pro Development Team*
